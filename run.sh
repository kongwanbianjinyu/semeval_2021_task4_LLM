
# run gpt-4o-mini model
python inference_LLM.py --base_url "" \
                        --model_api_identifier gpt-4o-mini \
                        --n_shots 2 \


# run gemma-2-9b-it for 2 shot
# python inference_LLM.py --base_url http://localhost:1234/v1 \
#                         --model_api_identifier gemma-2-9b-it \
#                         --n_shots 2 \

